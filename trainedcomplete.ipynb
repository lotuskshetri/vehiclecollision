{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9127858,"sourceType":"datasetVersion","datasetId":5510847}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n        # print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:33.344618Z","iopub.execute_input":"2025-01-26T14:26:33.344874Z","iopub.status.idle":"2025-01-26T14:26:34.149603Z","shell.execute_reply.started":"2025-01-26T14:26:33.344849Z","shell.execute_reply":"2025-01-26T14:26:34.148700Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install torch torchvision pillow numpy ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:34.150727Z","iopub.execute_input":"2025-01-26T14:26:34.151205Z","iopub.status.idle":"2025-01-26T14:26:38.536826Z","shell.execute_reply.started":"2025-01-26T14:26:34.151175Z","shell.execute_reply":"2025-01-26T14:26:38.535979Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"alirezachahardoli/vehicle-detection\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:38.537924Z","iopub.execute_input":"2025-01-26T14:26:38.538277Z","iopub.status.idle":"2025-01-26T14:26:39.021035Z","shell.execute_reply.started":"2025-01-26T14:26:38.538244Z","shell.execute_reply":"2025-01-26T14:26:39.020124Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/vehicle-detection\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!ls /kaggle/input/vehicle-detection/Vehicle_Detection/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:39.021842Z","iopub.execute_input":"2025-01-26T14:26:39.022053Z","iopub.status.idle":"2025-01-26T14:26:39.149115Z","shell.execute_reply.started":"2025-01-26T14:26:39.022034Z","shell.execute_reply":"2025-01-26T14:26:39.148162Z"}},"outputs":[{"name":"stdout","text":"test  train  valid  vehicles.yaml\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n\n# Path to your dataset directory\ndataset_path = \"/kaggle/input/vehicle-detection/Vehicle_Detection\"\n\n# List files and directories in the dataset path\nfor split in [\"train\", \"valid\", \"test\"]:\n    split_path = os.path.join(dataset_path, split, \"images\")\n    print(f\"{split.upper()} - Number of images: {len(os.listdir(split_path))}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:39.150164Z","iopub.execute_input":"2025-01-26T14:26:39.150437Z","iopub.status.idle":"2025-01-26T14:26:39.682923Z","shell.execute_reply.started":"2025-01-26T14:26:39.150413Z","shell.execute_reply":"2025-01-26T14:26:39.682173Z"}},"outputs":[{"name":"stdout","text":"TRAIN - Number of images: 12000\nVALID - Number of images: 2692\nTEST - Number of images: 1141\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import yaml\n\n# Path to the YAML file\nyaml_path = \"/kaggle/input/vehicle-detection/Vehicle_Detection/vehicles.yaml\"\n\n# Read the YAML file\nwith open(yaml_path, 'r') as file:\n    config = yaml.safe_load(file)\n\n# Display the contents\nprint(\"Contents of vehicles.yaml:\")\nprint(config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:39.685757Z","iopub.execute_input":"2025-01-26T14:26:39.685997Z","iopub.status.idle":"2025-01-26T14:26:39.718705Z","shell.execute_reply.started":"2025-01-26T14:26:39.685977Z","shell.execute_reply":"2025-01-26T14:26:39.717960Z"}},"outputs":[{"name":"stdout","text":"Contents of vehicles.yaml:\n{'path': '/Users/alireza/Desktop/', 'train': '/Users/alireza/Desktop/', 'val': '/Users/alireza/Desktop/', 'names': {0: 'Bus', 1: 'Truck', 2: 'Motorcycle', 3: 'Car'}}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import yaml\n\n# Define the updated configuration\nupdated_config = {\n    'path': '/kaggle/input/vehicle-detection/Vehicle_Detection',  # Base path to the dataset\n    'train': 'train/images',  # Path to training images relative to the base path\n    'val': 'valid/images',  # Path to validation images relative to the base path\n    'test': 'test/images',  # Path to test images relative to the base path\n    'names': {\n        0: 'Bus',\n        1: 'Truck',\n        2: 'Motorcycle',\n        3: 'Car'\n    }\n}\n\n# Path to save the updated YAML file\noutput_yaml_path = '/kaggle/working/vehicles.yaml'\n\n# Write the updated YAML file\nwith open(output_yaml_path, 'w') as file:\n    yaml.dump(updated_config, file)\n\nprint(f\"Updated vehicles.yaml saved to {output_yaml_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:39.720201Z","iopub.execute_input":"2025-01-26T14:26:39.720439Z","iopub.status.idle":"2025-01-26T14:26:39.727349Z","shell.execute_reply.started":"2025-01-26T14:26:39.720418Z","shell.execute_reply":"2025-01-26T14:26:39.726490Z"}},"outputs":[{"name":"stdout","text":"Updated vehicles.yaml saved to /kaggle/working/vehicles.yaml\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Verify the updated YAML file\nwith open(output_yaml_path, 'r') as file:\n    config = yaml.safe_load(file)\n\nprint(\"Updated YAML contents:\")\nprint(config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:39.728265Z","iopub.execute_input":"2025-01-26T14:26:39.728598Z","iopub.status.idle":"2025-01-26T14:26:39.744925Z","shell.execute_reply.started":"2025-01-26T14:26:39.728560Z","shell.execute_reply":"2025-01-26T14:26:39.744117Z"}},"outputs":[{"name":"stdout","text":"Updated YAML contents:\n{'names': {0: 'Bus', 1: 'Truck', 2: 'Motorcycle', 3: 'Car'}, 'path': '/kaggle/input/vehicle-detection/Vehicle_Detection', 'test': 'test/images', 'train': 'train/images', 'val': 'valid/images'}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def verify_dataset(dataset_path):\n    splits = ['train', 'valid', 'test']\n    for split in splits:\n        images_dir = os.path.join(dataset_path, split, 'images')\n        labels_dir = os.path.join(dataset_path, split, 'labels')\n        \n        images = os.listdir(images_dir)\n        labels = os.listdir(labels_dir)\n        \n        print(f\"{split.upper()} DATASET:\")\n        print(f\"  Images: {len(images)}\")\n        print(f\"  Labels: {len(labels)}\")\n        print(f\"  Mismatch: {len(images) - len(labels)}\\n\")\n\n# Run the verification\ndataset_path = \"/kaggle/input/vehicle-detection/Vehicle_Detection\"\nverify_dataset(dataset_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:39.745798Z","iopub.execute_input":"2025-01-26T14:26:39.746105Z","iopub.status.idle":"2025-01-26T14:26:40.362441Z","shell.execute_reply.started":"2025-01-26T14:26:39.746056Z","shell.execute_reply":"2025-01-26T14:26:40.361584Z"}},"outputs":[{"name":"stdout","text":"TRAIN DATASET:\n  Images: 12000\n  Labels: 12000\n  Mismatch: 0\n\nVALID DATASET:\n  Images: 2692\n  Labels: 2692\n  Mismatch: 0\n\nTEST DATASET:\n  Images: 1141\n  Labels: 1141\n  Mismatch: 0\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from PIL import Image\nimport torch\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dir, label_dir, transforms=None):\n        self.image_dir = image_dir\n        self.label_dir = label_dir\n        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])\n        self.label_files = sorted([f for f in os.listdir(label_dir) if f.endswith('.txt')])\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        # Load image\n        img_path = os.path.join(self.image_dir, self.image_files[idx])\n        img = Image.open(img_path).convert(\"RGB\")\n        img_width, img_height = img.size  # Get image dimensions\n        \n        # Load labels\n        label_path = os.path.join(self.label_dir, self.label_files[idx])\n        boxes = []\n        labels = []\n        with open(label_path, \"r\") as f:\n            for line in f.readlines():\n                data = list(map(float, line.strip().split()))\n                labels.append(int(data[0]))  # Class label\n                cx, cy, w, h = data[1:]  # Center coordinates and dimensions\n                # Convert [cx, cy, w, h] to [xmin, ymin, xmax, ymax]\n                xmin = (cx - w / 2) * img_width\n                ymin = (cy - h / 2) * img_height\n                xmax = (cx + w / 2) * img_width\n                ymax = (cy + h / 2) * img_height\n                boxes.append([xmin, ymin, xmax, ymax])\n\n\n\n        # Convert to tensors\n        boxes = torch.tensor(boxes, dtype=torch.float32)\n        labels = torch.tensor(labels, dtype=torch.int64)\n\n                # Skip samples without bounding boxes\n        if boxes.size(0) == 0:\n            return None\n        \n        # Create target dictionary\n        target = {\"boxes\": boxes, \"labels\": labels}\n\n        # Apply transformations\n        if self.transforms:\n            img = self.transforms(img)\n        \n        return img, target\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:40.363360Z","iopub.execute_input":"2025-01-26T14:26:40.363617Z","iopub.status.idle":"2025-01-26T14:26:43.649727Z","shell.execute_reply.started":"2025-01-26T14:26:40.363597Z","shell.execute_reply":"2025-01-26T14:26:43.649029Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Define transformations\nimport torchvision.transforms as T\n\ntransform = T.Compose([\n    T.ToTensor(),  # Convert image to PyTorch tensor\n])\n\n# Create datasets\ndataset = CustomDataset(\n    image_dir=\"/kaggle/input/vehicle-detection/Vehicle_Detection/train/images\",\n    label_dir=\"/kaggle/input/vehicle-detection/Vehicle_Detection/train/labels\",\n    transforms=transform\n)\n\n# Split dataset into training and validation sets\nindices = torch.randperm(len(dataset)).tolist()\ntrain_dataset = torch.utils.data.Subset(dataset, indices[:-50])\nvalid_dataset = torch.utils.data.Subset(dataset, indices[-50:])\n\n# Define custom collate function\ndef collate_fn(batch):\n    batch = [b for b in batch if b is not None]\n    return tuple(zip(*batch))\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\nvalid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n\nprint(f\"Train DataLoader has {len(train_loader)} batches\")\nprint(f\"Valid DataLoader has {len(valid_loader)} batches\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:43.650567Z","iopub.execute_input":"2025-01-26T14:26:43.650973Z","iopub.status.idle":"2025-01-26T14:26:46.144155Z","shell.execute_reply.started":"2025-01-26T14:26:43.650948Z","shell.execute_reply":"2025-01-26T14:26:46.143410Z"}},"outputs":[{"name":"stdout","text":"Train DataLoader has 747 batches\nValid DataLoader has 4 batches\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"for images, targets in train_loader:\n    print(images[0].shape)  # Should be a tensor with shape (C, H, W)\n    print(targets[0][\"boxes\"])  # Bounding boxes tensor\n    print(targets[0][\"labels\"])  # Labels tensor\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:46.144985Z","iopub.execute_input":"2025-01-26T14:26:46.145490Z","iopub.status.idle":"2025-01-26T14:26:46.529408Z","shell.execute_reply.started":"2025-01-26T14:26:46.145453Z","shell.execute_reply":"2025-01-26T14:26:46.528505Z"}},"outputs":[{"name":"stdout","text":"torch.Size([3, 640, 640])\ntensor([[ 85.,  73., 539., 508.]])\ntensor([3])\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"for images, targets in train_loader:\n    print(\"Image size:\", images[0].shape)\n    print(\"Bounding boxes:\", targets[0][\"boxes\"])\n    print(\"Labels:\", targets[0][\"labels\"])\n    break  # Remove this to check more samples\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:46.530314Z","iopub.execute_input":"2025-01-26T14:26:46.530575Z","iopub.status.idle":"2025-01-26T14:26:46.821436Z","shell.execute_reply.started":"2025-01-26T14:26:46.530551Z","shell.execute_reply":"2025-01-26T14:26:46.820550Z"}},"outputs":[{"name":"stdout","text":"Image size: torch.Size([3, 416, 416])\nBounding boxes: tensor([[ 29.2500,  28.0000, 381.7500, 398.0000]])\nLabels: tensor([1])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\n# Load pre-trained Faster R-CNN model\nmodel = fasterrcnn_resnet50_fpn(pretrained=True)\n\n# Number of classes (your dataset classes + background)\nnum_classes = 4  # For example, 3 classes (vehicles) + background\n\n# Get the number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# Replace the head of the model with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:46.822295Z","iopub.execute_input":"2025-01-26T14:26:46.822544Z","iopub.status.idle":"2025-01-26T14:26:48.438791Z","shell.execute_reply.started":"2025-01-26T14:26:46.822521Z","shell.execute_reply":"2025-01-26T14:26:48.438124Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n100%|██████████| 160M/160M [00:00<00:00, 197MB/s]  \n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# if torch.cuda.device_count() > 1:\n#     print(f\"Using {torch.cuda.device_count()} GPUs!\")\n#     model = torch.nn.DataParallel(model)  # Wrap the model for multi-GPU support","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:48.439624Z","iopub.execute_input":"2025-01-26T14:26:48.439922Z","iopub.status.idle":"2025-01-26T14:26:48.443155Z","shell.execute_reply.started":"2025-01-26T14:26:48.439893Z","shell.execute_reply":"2025-01-26T14:26:48.442473Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:48.443961Z","iopub.execute_input":"2025-01-26T14:26:48.444245Z","iopub.status.idle":"2025-01-26T14:26:48.773814Z","shell.execute_reply.started":"2025-01-26T14:26:48.444212Z","shell.execute_reply":"2025-01-26T14:26:48.772912Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import torch\n\n# Check if CUDA is available\nprint(\"CUDA available:\", torch.cuda.is_available())\n\n# Check the number of GPUs\nprint(\"Number of GPUs:\", torch.cuda.device_count())\n\n# Print GPU names\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:48.774641Z","iopub.execute_input":"2025-01-26T14:26:48.774884Z","iopub.status.idle":"2025-01-26T14:26:48.780530Z","shell.execute_reply.started":"2025-01-26T14:26:48.774863Z","shell.execute_reply":"2025-01-26T14:26:48.779873Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nNumber of GPUs: 2\nGPU 0: Tesla T4\nGPU 1: Tesla T4\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Optimizer\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n\n# Learning rate scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:48.781643Z","iopub.execute_input":"2025-01-26T14:26:48.781975Z","iopub.status.idle":"2025-01-26T14:26:48.794397Z","shell.execute_reply.started":"2025-01-26T14:26:48.781946Z","shell.execute_reply":"2025-01-26T14:26:48.793656Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"num_epochs = 1\n\nfor epoch in range(num_epochs):\n    print(f\"Starting epoch {epoch + 1}/{num_epochs}...\")  # Debug\n\n    model.train()\n    train_loss = 0.0\n\n    for batch_idx, (images, targets) in enumerate(train_loader):\n        print(f\"Processing batch {batch_idx + 1}/{len(train_loader)}...\")  # Debug\n        \n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n\n        # Backward pass\n        losses.backward()\n        optimizer.step()\n\n        train_loss += losses.item()\n\n        # Print loss for the current batch\n        if (batch_idx + 1) % 10 == 0:  # Adjust frequency as needed\n            print(f\"Batch {batch_idx + 1}/{len(train_loader)}, Loss: {losses.item():.4f}\")\n            torch.cuda.empty_cache()\n\n    # Update learning rate\n    lr_scheduler.step()\n\n    print(f\"Epoch {epoch + 1}/{num_epochs} completed, Average Loss: {train_loss / len(train_loader):.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:26:48.797682Z","iopub.execute_input":"2025-01-26T14:26:48.797882Z","iopub.status.idle":"2025-01-26T15:04:53.599810Z","shell.execute_reply.started":"2025-01-26T14:26:48.797864Z","shell.execute_reply":"2025-01-26T15:04:53.598875Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Starting epoch 1/1...\nProcessing batch 1/747...\nProcessing batch 2/747...\nProcessing batch 3/747...\nProcessing batch 4/747...\nProcessing batch 5/747...\nProcessing batch 6/747...\nProcessing batch 7/747...\nProcessing batch 8/747...\nProcessing batch 9/747...\nProcessing batch 10/747...\nBatch 10/747, Loss: 0.2894\nProcessing batch 11/747...\nProcessing batch 12/747...\nProcessing batch 13/747...\nProcessing batch 14/747...\nProcessing batch 15/747...\nProcessing batch 16/747...\nProcessing batch 17/747...\nProcessing batch 18/747...\nProcessing batch 19/747...\nProcessing batch 20/747...\nBatch 20/747, Loss: 0.1654\nProcessing batch 21/747...\nProcessing batch 22/747...\nProcessing batch 23/747...\nProcessing batch 24/747...\nProcessing batch 25/747...\nProcessing batch 26/747...\nProcessing batch 27/747...\nProcessing batch 28/747...\nProcessing batch 29/747...\nProcessing batch 30/747...\nBatch 30/747, Loss: 0.2157\nProcessing batch 31/747...\nProcessing batch 32/747...\nProcessing batch 33/747...\nProcessing batch 34/747...\nProcessing batch 35/747...\nProcessing batch 36/747...\nProcessing batch 37/747...\nProcessing batch 38/747...\nProcessing batch 39/747...\nProcessing batch 40/747...\nBatch 40/747, Loss: 0.1524\nProcessing batch 41/747...\nProcessing batch 42/747...\nProcessing batch 43/747...\nProcessing batch 44/747...\nProcessing batch 45/747...\nProcessing batch 46/747...\nProcessing batch 47/747...\nProcessing batch 48/747...\nProcessing batch 49/747...\nProcessing batch 50/747...\nBatch 50/747, Loss: 0.0939\nProcessing batch 51/747...\nProcessing batch 52/747...\nProcessing batch 53/747...\nProcessing batch 54/747...\nProcessing batch 55/747...\nProcessing batch 56/747...\nProcessing batch 57/747...\nProcessing batch 58/747...\nProcessing batch 59/747...\nProcessing batch 60/747...\nBatch 60/747, Loss: 0.1312\nProcessing batch 61/747...\nProcessing batch 62/747...\nProcessing batch 63/747...\nProcessing batch 64/747...\nProcessing batch 65/747...\nProcessing batch 66/747...\nProcessing batch 67/747...\nProcessing batch 68/747...\nProcessing batch 69/747...\nProcessing batch 70/747...\nBatch 70/747, Loss: 0.1632\nProcessing batch 71/747...\nProcessing batch 72/747...\nProcessing batch 73/747...\nProcessing batch 74/747...\nProcessing batch 75/747...\nProcessing batch 76/747...\nProcessing batch 77/747...\nProcessing batch 78/747...\nProcessing batch 79/747...\nProcessing batch 80/747...\nBatch 80/747, Loss: 0.1221\nProcessing batch 81/747...\nProcessing batch 82/747...\nProcessing batch 83/747...\nProcessing batch 84/747...\nProcessing batch 85/747...\nProcessing batch 86/747...\nProcessing batch 87/747...\nProcessing batch 88/747...\nProcessing batch 89/747...\nProcessing batch 90/747...\nBatch 90/747, Loss: 0.1282\nProcessing batch 91/747...\nProcessing batch 92/747...\nProcessing batch 93/747...\nProcessing batch 94/747...\nProcessing batch 95/747...\nProcessing batch 96/747...\nProcessing batch 97/747...\nProcessing batch 98/747...\nProcessing batch 99/747...\nProcessing batch 100/747...\nBatch 100/747, Loss: 0.1250\nProcessing batch 101/747...\nProcessing batch 102/747...\nProcessing batch 103/747...\nProcessing batch 104/747...\nProcessing batch 105/747...\nProcessing batch 106/747...\nProcessing batch 107/747...\nProcessing batch 108/747...\nProcessing batch 109/747...\nProcessing batch 110/747...\nBatch 110/747, Loss: 0.1326\nProcessing batch 111/747...\nProcessing batch 112/747...\nProcessing batch 113/747...\nProcessing batch 114/747...\nProcessing batch 115/747...\nProcessing batch 116/747...\nProcessing batch 117/747...\nProcessing batch 118/747...\nProcessing batch 119/747...\nProcessing batch 120/747...\nBatch 120/747, Loss: 0.1206\nProcessing batch 121/747...\nProcessing batch 122/747...\nProcessing batch 123/747...\nProcessing batch 124/747...\nProcessing batch 125/747...\nProcessing batch 126/747...\nProcessing batch 127/747...\nProcessing batch 128/747...\nProcessing batch 129/747...\nProcessing batch 130/747...\nBatch 130/747, Loss: 0.0687\nProcessing batch 131/747...\nProcessing batch 132/747...\nProcessing batch 133/747...\nProcessing batch 134/747...\nProcessing batch 135/747...\nProcessing batch 136/747...\nProcessing batch 137/747...\nProcessing batch 138/747...\nProcessing batch 139/747...\nProcessing batch 140/747...\nBatch 140/747, Loss: 0.0869\nProcessing batch 141/747...\nProcessing batch 142/747...\nProcessing batch 143/747...\nProcessing batch 144/747...\nProcessing batch 145/747...\nProcessing batch 146/747...\nProcessing batch 147/747...\nProcessing batch 148/747...\nProcessing batch 149/747...\nProcessing batch 150/747...\nBatch 150/747, Loss: 0.1108\nProcessing batch 151/747...\nProcessing batch 152/747...\nProcessing batch 153/747...\nProcessing batch 154/747...\nProcessing batch 155/747...\nProcessing batch 156/747...\nProcessing batch 157/747...\nProcessing batch 158/747...\nProcessing batch 159/747...\nProcessing batch 160/747...\nBatch 160/747, Loss: 0.0754\nProcessing batch 161/747...\nProcessing batch 162/747...\nProcessing batch 163/747...\nProcessing batch 164/747...\nProcessing batch 165/747...\nProcessing batch 166/747...\nProcessing batch 167/747...\nProcessing batch 168/747...\nProcessing batch 169/747...\nProcessing batch 170/747...\nBatch 170/747, Loss: 0.0805\nProcessing batch 171/747...\nProcessing batch 172/747...\nProcessing batch 173/747...\nProcessing batch 174/747...\nProcessing batch 175/747...\nProcessing batch 176/747...\nProcessing batch 177/747...\nProcessing batch 178/747...\nProcessing batch 179/747...\nProcessing batch 180/747...\nBatch 180/747, Loss: 0.0653\nProcessing batch 181/747...\nProcessing batch 182/747...\nProcessing batch 183/747...\nProcessing batch 184/747...\nProcessing batch 185/747...\nProcessing batch 186/747...\nProcessing batch 187/747...\nProcessing batch 188/747...\nProcessing batch 189/747...\nProcessing batch 190/747...\nBatch 190/747, Loss: 0.0781\nProcessing batch 191/747...\nProcessing batch 192/747...\nProcessing batch 193/747...\nProcessing batch 194/747...\nProcessing batch 195/747...\nProcessing batch 196/747...\nProcessing batch 197/747...\nProcessing batch 198/747...\nProcessing batch 199/747...\nProcessing batch 200/747...\nBatch 200/747, Loss: 0.0612\nProcessing batch 201/747...\nProcessing batch 202/747...\nProcessing batch 203/747...\nProcessing batch 204/747...\nProcessing batch 205/747...\nProcessing batch 206/747...\nProcessing batch 207/747...\nProcessing batch 208/747...\nProcessing batch 209/747...\nProcessing batch 210/747...\nBatch 210/747, Loss: 0.0751\nProcessing batch 211/747...\nProcessing batch 212/747...\nProcessing batch 213/747...\nProcessing batch 214/747...\nProcessing batch 215/747...\nProcessing batch 216/747...\nProcessing batch 217/747...\nProcessing batch 218/747...\nProcessing batch 219/747...\nProcessing batch 220/747...\nBatch 220/747, Loss: 0.0767\nProcessing batch 221/747...\nProcessing batch 222/747...\nProcessing batch 223/747...\nProcessing batch 224/747...\nProcessing batch 225/747...\nProcessing batch 226/747...\nProcessing batch 227/747...\nProcessing batch 228/747...\nProcessing batch 229/747...\nProcessing batch 230/747...\nBatch 230/747, Loss: 0.1143\nProcessing batch 231/747...\nProcessing batch 232/747...\nProcessing batch 233/747...\nProcessing batch 234/747...\nProcessing batch 235/747...\nProcessing batch 236/747...\nProcessing batch 237/747...\nProcessing batch 238/747...\nProcessing batch 239/747...\nProcessing batch 240/747...\nBatch 240/747, Loss: 0.1252\nProcessing batch 241/747...\nProcessing batch 242/747...\nProcessing batch 243/747...\nProcessing batch 244/747...\nProcessing batch 245/747...\nProcessing batch 246/747...\nProcessing batch 247/747...\nProcessing batch 248/747...\nProcessing batch 249/747...\nProcessing batch 250/747...\nBatch 250/747, Loss: 0.0858\nProcessing batch 251/747...\nProcessing batch 252/747...\nProcessing batch 253/747...\nProcessing batch 254/747...\nProcessing batch 255/747...\nProcessing batch 256/747...\nProcessing batch 257/747...\nProcessing batch 258/747...\nProcessing batch 259/747...\nProcessing batch 260/747...\nBatch 260/747, Loss: 0.0598\nProcessing batch 261/747...\nProcessing batch 262/747...\nProcessing batch 263/747...\nProcessing batch 264/747...\nProcessing batch 265/747...\nProcessing batch 266/747...\nProcessing batch 267/747...\nProcessing batch 268/747...\nProcessing batch 269/747...\nProcessing batch 270/747...\nBatch 270/747, Loss: 0.0880\nProcessing batch 271/747...\nProcessing batch 272/747...\nProcessing batch 273/747...\nProcessing batch 274/747...\nProcessing batch 275/747...\nProcessing batch 276/747...\nProcessing batch 277/747...\nProcessing batch 278/747...\nProcessing batch 279/747...\nProcessing batch 280/747...\nBatch 280/747, Loss: 0.0670\nProcessing batch 281/747...\nProcessing batch 282/747...\nProcessing batch 283/747...\nProcessing batch 284/747...\nProcessing batch 285/747...\nProcessing batch 286/747...\nProcessing batch 287/747...\nProcessing batch 288/747...\nProcessing batch 289/747...\nProcessing batch 290/747...\nBatch 290/747, Loss: 0.0578\nProcessing batch 291/747...\nProcessing batch 292/747...\nProcessing batch 293/747...\nProcessing batch 294/747...\nProcessing batch 295/747...\nProcessing batch 296/747...\nProcessing batch 297/747...\nProcessing batch 298/747...\nProcessing batch 299/747...\nProcessing batch 300/747...\nBatch 300/747, Loss: 0.0953\nProcessing batch 301/747...\nProcessing batch 302/747...\nProcessing batch 303/747...\nProcessing batch 304/747...\nProcessing batch 305/747...\nProcessing batch 306/747...\nProcessing batch 307/747...\nProcessing batch 308/747...\nProcessing batch 309/747...\nProcessing batch 310/747...\nBatch 310/747, Loss: 0.0534\nProcessing batch 311/747...\nProcessing batch 312/747...\nProcessing batch 313/747...\nProcessing batch 314/747...\nProcessing batch 315/747...\nProcessing batch 316/747...\nProcessing batch 317/747...\nProcessing batch 318/747...\nProcessing batch 319/747...\nProcessing batch 320/747...\nBatch 320/747, Loss: 0.0776\nProcessing batch 321/747...\nProcessing batch 322/747...\nProcessing batch 323/747...\nProcessing batch 324/747...\nProcessing batch 325/747...\nProcessing batch 326/747...\nProcessing batch 327/747...\nProcessing batch 328/747...\nProcessing batch 329/747...\nProcessing batch 330/747...\nBatch 330/747, Loss: 0.1038\nProcessing batch 331/747...\nProcessing batch 332/747...\nProcessing batch 333/747...\nProcessing batch 334/747...\nProcessing batch 335/747...\nProcessing batch 336/747...\nProcessing batch 337/747...\nProcessing batch 338/747...\nProcessing batch 339/747...\nProcessing batch 340/747...\nBatch 340/747, Loss: 0.0468\nProcessing batch 341/747...\nProcessing batch 342/747...\nProcessing batch 343/747...\nProcessing batch 344/747...\nProcessing batch 345/747...\nProcessing batch 346/747...\nProcessing batch 347/747...\nProcessing batch 348/747...\nProcessing batch 349/747...\nProcessing batch 350/747...\nBatch 350/747, Loss: 0.0602\nProcessing batch 351/747...\nProcessing batch 352/747...\nProcessing batch 353/747...\nProcessing batch 354/747...\nProcessing batch 355/747...\nProcessing batch 356/747...\nProcessing batch 357/747...\nProcessing batch 358/747...\nProcessing batch 359/747...\nProcessing batch 360/747...\nBatch 360/747, Loss: 0.0484\nProcessing batch 361/747...\nProcessing batch 362/747...\nProcessing batch 363/747...\nProcessing batch 364/747...\nProcessing batch 365/747...\nProcessing batch 366/747...\nProcessing batch 367/747...\nProcessing batch 368/747...\nProcessing batch 369/747...\nProcessing batch 370/747...\nBatch 370/747, Loss: 0.0517\nProcessing batch 371/747...\nProcessing batch 372/747...\nProcessing batch 373/747...\nProcessing batch 374/747...\nProcessing batch 375/747...\nProcessing batch 376/747...\nProcessing batch 377/747...\nProcessing batch 378/747...\nProcessing batch 379/747...\nProcessing batch 380/747...\nBatch 380/747, Loss: 0.0625\nProcessing batch 381/747...\nProcessing batch 382/747...\nProcessing batch 383/747...\nProcessing batch 384/747...\nProcessing batch 385/747...\nProcessing batch 386/747...\nProcessing batch 387/747...\nProcessing batch 388/747...\nProcessing batch 389/747...\nProcessing batch 390/747...\nBatch 390/747, Loss: 0.0881\nProcessing batch 391/747...\nProcessing batch 392/747...\nProcessing batch 393/747...\nProcessing batch 394/747...\nProcessing batch 395/747...\nProcessing batch 396/747...\nProcessing batch 397/747...\nProcessing batch 398/747...\nProcessing batch 399/747...\nProcessing batch 400/747...\nBatch 400/747, Loss: 0.0410\nProcessing batch 401/747...\nProcessing batch 402/747...\nProcessing batch 403/747...\nProcessing batch 404/747...\nProcessing batch 405/747...\nProcessing batch 406/747...\nProcessing batch 407/747...\nProcessing batch 408/747...\nProcessing batch 409/747...\nProcessing batch 410/747...\nBatch 410/747, Loss: 0.0646\nProcessing batch 411/747...\nProcessing batch 412/747...\nProcessing batch 413/747...\nProcessing batch 414/747...\nProcessing batch 415/747...\nProcessing batch 416/747...\nProcessing batch 417/747...\nProcessing batch 418/747...\nProcessing batch 419/747...\nProcessing batch 420/747...\nBatch 420/747, Loss: 0.0535\nProcessing batch 421/747...\nProcessing batch 422/747...\nProcessing batch 423/747...\nProcessing batch 424/747...\nProcessing batch 425/747...\nProcessing batch 426/747...\nProcessing batch 427/747...\nProcessing batch 428/747...\nProcessing batch 429/747...\nProcessing batch 430/747...\nBatch 430/747, Loss: 0.0558\nProcessing batch 431/747...\nProcessing batch 432/747...\nProcessing batch 433/747...\nProcessing batch 434/747...\nProcessing batch 435/747...\nProcessing batch 436/747...\nProcessing batch 437/747...\nProcessing batch 438/747...\nProcessing batch 439/747...\nProcessing batch 440/747...\nBatch 440/747, Loss: 0.0508\nProcessing batch 441/747...\nProcessing batch 442/747...\nProcessing batch 443/747...\nProcessing batch 444/747...\nProcessing batch 445/747...\nProcessing batch 446/747...\nProcessing batch 447/747...\nProcessing batch 448/747...\nProcessing batch 449/747...\nProcessing batch 450/747...\nBatch 450/747, Loss: 0.0584\nProcessing batch 451/747...\nProcessing batch 452/747...\nProcessing batch 453/747...\nProcessing batch 454/747...\nProcessing batch 455/747...\nProcessing batch 456/747...\nProcessing batch 457/747...\nProcessing batch 458/747...\nProcessing batch 459/747...\nProcessing batch 460/747...\nBatch 460/747, Loss: 0.0590\nProcessing batch 461/747...\nProcessing batch 462/747...\nProcessing batch 463/747...\nProcessing batch 464/747...\nProcessing batch 465/747...\nProcessing batch 466/747...\nProcessing batch 467/747...\nProcessing batch 468/747...\nProcessing batch 469/747...\nProcessing batch 470/747...\nBatch 470/747, Loss: 0.0553\nProcessing batch 471/747...\nProcessing batch 472/747...\nProcessing batch 473/747...\nProcessing batch 474/747...\nProcessing batch 475/747...\nProcessing batch 476/747...\nProcessing batch 477/747...\nProcessing batch 478/747...\nProcessing batch 479/747...\nProcessing batch 480/747...\nBatch 480/747, Loss: 0.0427\nProcessing batch 481/747...\nProcessing batch 482/747...\nProcessing batch 483/747...\nProcessing batch 484/747...\nProcessing batch 485/747...\nProcessing batch 486/747...\nProcessing batch 487/747...\nProcessing batch 488/747...\nProcessing batch 489/747...\nProcessing batch 490/747...\nBatch 490/747, Loss: 0.0500\nProcessing batch 491/747...\nProcessing batch 492/747...\nProcessing batch 493/747...\nProcessing batch 494/747...\nProcessing batch 495/747...\nProcessing batch 496/747...\nProcessing batch 497/747...\nProcessing batch 498/747...\nProcessing batch 499/747...\nProcessing batch 500/747...\nBatch 500/747, Loss: 0.0571\nProcessing batch 501/747...\nProcessing batch 502/747...\nProcessing batch 503/747...\nProcessing batch 504/747...\nProcessing batch 505/747...\nProcessing batch 506/747...\nProcessing batch 507/747...\nProcessing batch 508/747...\nProcessing batch 509/747...\nProcessing batch 510/747...\nBatch 510/747, Loss: 0.0449\nProcessing batch 511/747...\nProcessing batch 512/747...\nProcessing batch 513/747...\nProcessing batch 514/747...\nProcessing batch 515/747...\nProcessing batch 516/747...\nProcessing batch 517/747...\nProcessing batch 518/747...\nProcessing batch 519/747...\nProcessing batch 520/747...\nBatch 520/747, Loss: 0.0482\nProcessing batch 521/747...\nProcessing batch 522/747...\nProcessing batch 523/747...\nProcessing batch 524/747...\nProcessing batch 525/747...\nProcessing batch 526/747...\nProcessing batch 527/747...\nProcessing batch 528/747...\nProcessing batch 529/747...\nProcessing batch 530/747...\nBatch 530/747, Loss: 0.0557\nProcessing batch 531/747...\nProcessing batch 532/747...\nProcessing batch 533/747...\nProcessing batch 534/747...\nProcessing batch 535/747...\nProcessing batch 536/747...\nProcessing batch 537/747...\nProcessing batch 538/747...\nProcessing batch 539/747...\nProcessing batch 540/747...\nBatch 540/747, Loss: 0.0460\nProcessing batch 541/747...\nProcessing batch 542/747...\nProcessing batch 543/747...\nProcessing batch 544/747...\nProcessing batch 545/747...\nProcessing batch 546/747...\nProcessing batch 547/747...\nProcessing batch 548/747...\nProcessing batch 549/747...\nProcessing batch 550/747...\nBatch 550/747, Loss: 0.0583\nProcessing batch 551/747...\nProcessing batch 552/747...\nProcessing batch 553/747...\nProcessing batch 554/747...\nProcessing batch 555/747...\nProcessing batch 556/747...\nProcessing batch 557/747...\nProcessing batch 558/747...\nProcessing batch 559/747...\nProcessing batch 560/747...\nBatch 560/747, Loss: 0.0965\nProcessing batch 561/747...\nProcessing batch 562/747...\nProcessing batch 563/747...\nProcessing batch 564/747...\nProcessing batch 565/747...\nProcessing batch 566/747...\nProcessing batch 567/747...\nProcessing batch 568/747...\nProcessing batch 569/747...\nProcessing batch 570/747...\nBatch 570/747, Loss: 0.0421\nProcessing batch 571/747...\nProcessing batch 572/747...\nProcessing batch 573/747...\nProcessing batch 574/747...\nProcessing batch 575/747...\nProcessing batch 576/747...\nProcessing batch 577/747...\nProcessing batch 578/747...\nProcessing batch 579/747...\nProcessing batch 580/747...\nBatch 580/747, Loss: 0.0692\nProcessing batch 581/747...\nProcessing batch 582/747...\nProcessing batch 583/747...\nProcessing batch 584/747...\nProcessing batch 585/747...\nProcessing batch 586/747...\nProcessing batch 587/747...\nProcessing batch 588/747...\nProcessing batch 589/747...\nProcessing batch 590/747...\nBatch 590/747, Loss: 0.0556\nProcessing batch 591/747...\nProcessing batch 592/747...\nProcessing batch 593/747...\nProcessing batch 594/747...\nProcessing batch 595/747...\nProcessing batch 596/747...\nProcessing batch 597/747...\nProcessing batch 598/747...\nProcessing batch 599/747...\nProcessing batch 600/747...\nBatch 600/747, Loss: 0.0674\nProcessing batch 601/747...\nProcessing batch 602/747...\nProcessing batch 603/747...\nProcessing batch 604/747...\nProcessing batch 605/747...\nProcessing batch 606/747...\nProcessing batch 607/747...\nProcessing batch 608/747...\nProcessing batch 609/747...\nProcessing batch 610/747...\nBatch 610/747, Loss: 0.0529\nProcessing batch 611/747...\nProcessing batch 612/747...\nProcessing batch 613/747...\nProcessing batch 614/747...\nProcessing batch 615/747...\nProcessing batch 616/747...\nProcessing batch 617/747...\nProcessing batch 618/747...\nProcessing batch 619/747...\nProcessing batch 620/747...\nBatch 620/747, Loss: 0.0551\nProcessing batch 621/747...\nProcessing batch 622/747...\nProcessing batch 623/747...\nProcessing batch 624/747...\nProcessing batch 625/747...\nProcessing batch 626/747...\nProcessing batch 627/747...\nProcessing batch 628/747...\nProcessing batch 629/747...\nProcessing batch 630/747...\nBatch 630/747, Loss: 0.0468\nProcessing batch 631/747...\nProcessing batch 632/747...\nProcessing batch 633/747...\nProcessing batch 634/747...\nProcessing batch 635/747...\nProcessing batch 636/747...\nProcessing batch 637/747...\nProcessing batch 638/747...\nProcessing batch 639/747...\nProcessing batch 640/747...\nBatch 640/747, Loss: 0.0517\nProcessing batch 641/747...\nProcessing batch 642/747...\nProcessing batch 643/747...\nProcessing batch 644/747...\nProcessing batch 645/747...\nProcessing batch 646/747...\nProcessing batch 647/747...\nProcessing batch 648/747...\nProcessing batch 649/747...\nProcessing batch 650/747...\nBatch 650/747, Loss: 0.0571\nProcessing batch 651/747...\nProcessing batch 652/747...\nProcessing batch 653/747...\nProcessing batch 654/747...\nProcessing batch 655/747...\nProcessing batch 656/747...\nProcessing batch 657/747...\nProcessing batch 658/747...\nProcessing batch 659/747...\nProcessing batch 660/747...\nBatch 660/747, Loss: 0.0584\nProcessing batch 661/747...\nProcessing batch 662/747...\nProcessing batch 663/747...\nProcessing batch 664/747...\nProcessing batch 665/747...\nProcessing batch 666/747...\nProcessing batch 667/747...\nProcessing batch 668/747...\nProcessing batch 669/747...\nProcessing batch 670/747...\nBatch 670/747, Loss: 0.0460\nProcessing batch 671/747...\nProcessing batch 672/747...\nProcessing batch 673/747...\nProcessing batch 674/747...\nProcessing batch 675/747...\nProcessing batch 676/747...\nProcessing batch 677/747...\nProcessing batch 678/747...\nProcessing batch 679/747...\nProcessing batch 680/747...\nBatch 680/747, Loss: 0.1138\nProcessing batch 681/747...\nProcessing batch 682/747...\nProcessing batch 683/747...\nProcessing batch 684/747...\nProcessing batch 685/747...\nProcessing batch 686/747...\nProcessing batch 687/747...\nProcessing batch 688/747...\nProcessing batch 689/747...\nProcessing batch 690/747...\nBatch 690/747, Loss: 0.0563\nProcessing batch 691/747...\nProcessing batch 692/747...\nProcessing batch 693/747...\nProcessing batch 694/747...\nProcessing batch 695/747...\nProcessing batch 696/747...\nProcessing batch 697/747...\nProcessing batch 698/747...\nProcessing batch 699/747...\nProcessing batch 700/747...\nBatch 700/747, Loss: 0.0646\nProcessing batch 701/747...\nProcessing batch 702/747...\nProcessing batch 703/747...\nProcessing batch 704/747...\nProcessing batch 705/747...\nProcessing batch 706/747...\nProcessing batch 707/747...\nProcessing batch 708/747...\nProcessing batch 709/747...\nProcessing batch 710/747...\nBatch 710/747, Loss: 0.0416\nProcessing batch 711/747...\nProcessing batch 712/747...\nProcessing batch 713/747...\nProcessing batch 714/747...\nProcessing batch 715/747...\nProcessing batch 716/747...\nProcessing batch 717/747...\nProcessing batch 718/747...\nProcessing batch 719/747...\nProcessing batch 720/747...\nBatch 720/747, Loss: 0.0469\nProcessing batch 721/747...\nProcessing batch 722/747...\nProcessing batch 723/747...\nProcessing batch 724/747...\nProcessing batch 725/747...\nProcessing batch 726/747...\nProcessing batch 727/747...\nProcessing batch 728/747...\nProcessing batch 729/747...\nProcessing batch 730/747...\nBatch 730/747, Loss: 0.0629\nProcessing batch 731/747...\nProcessing batch 732/747...\nProcessing batch 733/747...\nProcessing batch 734/747...\nProcessing batch 735/747...\nProcessing batch 736/747...\nProcessing batch 737/747...\nProcessing batch 738/747...\nProcessing batch 739/747...\nProcessing batch 740/747...\nBatch 740/747, Loss: 0.0575\nProcessing batch 741/747...\nProcessing batch 742/747...\nProcessing batch 743/747...\nProcessing batch 744/747...\nProcessing batch 745/747...\nProcessing batch 746/747...\nProcessing batch 747/747...\nEpoch 1/1 completed, Average Loss: 0.0831\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:04:53.601003Z","iopub.execute_input":"2025-01-26T15:04:53.601280Z","iopub.status.idle":"2025-01-26T15:04:53.637682Z","shell.execute_reply.started":"2025-01-26T15:04:53.601257Z","shell.execute_reply":"2025-01-26T15:04:53.636868Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Save the model's state dictionary\nmodel_path = \"/kaggle/working/fasterrcnn_model.pth\"\ntorch.save(model.state_dict(), model_path)\nprint(f\"Model saved to {model_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:10:36.346355Z","iopub.execute_input":"2025-01-26T15:10:36.346654Z","iopub.status.idle":"2025-01-26T15:10:36.797485Z","shell.execute_reply.started":"2025-01-26T15:10:36.346630Z","shell.execute_reply":"2025-01-26T15:10:36.796185Z"}},"outputs":[{"name":"stdout","text":"Model saved to /kaggle/working/fasterrcnn_model.pth\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Generate a download link for the saved model\nFileLink(model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:10:41.751879Z","iopub.execute_input":"2025-01-26T15:10:41.752225Z","iopub.status.idle":"2025-01-26T15:10:41.758127Z","shell.execute_reply.started":"2025-01-26T15:10:41.752197Z","shell.execute_reply":"2025-01-26T15:10:41.757019Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fasterrcnn_model.pth","text/html":"<a href='/kaggle/working/fasterrcnn_model.pth' target='_blank'>/kaggle/working/fasterrcnn_model.pth</a><br>"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import precision_recall_curve, auc\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:13:22.681108Z","iopub.execute_input":"2025-01-26T15:13:22.681452Z","iopub.status.idle":"2025-01-26T15:13:22.685596Z","shell.execute_reply.started":"2025-01-26T15:13:22.681411Z","shell.execute_reply":"2025-01-26T15:13:22.684505Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"model = fasterrcnn_resnet50_fpn(weights=None)\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\nmodel.load_state_dict(torch.load('/kaggle/working/fasterrcnn_model.pth'))\nmodel = model.to(device)\nmodel.eval()\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:36:42.091345Z","iopub.execute_input":"2025-01-26T15:36:42.091709Z","iopub.status.idle":"2025-01-26T15:36:42.975046Z","shell.execute_reply.started":"2025-01-26T15:36:42.091678Z","shell.execute_reply":"2025-01-26T15:36:42.974268Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-41-5e9baf130864>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/fasterrcnn_model.pth'))\n","output_type":"stream"},{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"from torchvision.ops import box_iou\n\ndef compute_iou(pred_boxes, gt_boxes):\n    \"\"\"\n    Computes IoU between predicted and ground-truth boxes.\n    Args:\n        pred_boxes (Tensor): Predicted bounding boxes [N, 4]\n        gt_boxes (Tensor): Ground-truth bounding boxes [M, 4]\n    Returns:\n        iou (Tensor): IoU matrix [N, M]\n    \"\"\"\n    return box_iou(pred_boxes, gt_boxes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:13:28.323786Z","iopub.execute_input":"2025-01-26T15:13:28.324102Z","iopub.status.idle":"2025-01-26T15:13:28.328526Z","shell.execute_reply.started":"2025-01-26T15:13:28.324076Z","shell.execute_reply":"2025-01-26T15:13:28.327509Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def evaluate_model(model, data_loader, device, iou_threshold=0.5):\n    \"\"\"\n    Evaluates the model using mAP and recall metrics.\n    Args:\n        model: Trained Faster R-CNN model.\n        data_loader: DataLoader for validation/test dataset.\n        device: Device (CPU or GPU).\n        iou_threshold: IoU threshold for considering a positive match.\n    Returns:\n        mean_average_precision (float): mAP for the dataset.\n        recall (float): Recall metric for the dataset.\n    \"\"\"\n    model.eval()\n    all_precisions, all_recalls = [], []\n    total_true_positives, total_false_positives, total_false_negatives = 0, 0, 0\n\n    with torch.no_grad():\n        for images, targets in data_loader:\n            images = list(image.to(device) for image in images)\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n            # Forward pass\n            outputs = model(images)\n\n            for target, output in zip(targets, outputs):\n                gt_boxes = target[\"boxes\"]\n                gt_labels = target[\"labels\"]\n                pred_boxes = output[\"boxes\"]\n                pred_scores = output[\"scores\"]\n                pred_labels = output[\"labels\"]\n\n                # Match predicted boxes to ground-truth boxes\n                ious = compute_iou(pred_boxes, gt_boxes)\n                true_positives = (ious > iou_threshold).sum().item()\n                false_positives = pred_boxes.size(0) - true_positives\n                false_negatives = gt_boxes.size(0) - true_positives\n\n                total_true_positives += true_positives\n                total_false_positives += false_positives\n                total_false_negatives += false_negatives\n\n                # Compute precision and recall for the batch\n                precision = true_positives / (true_positives + false_positives + 1e-6)\n                recall = true_positives / (true_positives + false_negatives + 1e-6)\n\n                all_precisions.append(precision)\n                all_recalls.append(recall)\n\n    # Overall metrics\n    mean_average_precision = np.mean(all_precisions)\n    recall = np.mean(all_recalls)\n\n    print(f\"mAP: {mean_average_precision:.4f}, Recall: {recall:.4f}\")\n    return mean_average_precision, recall\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:14:18.299246Z","iopub.execute_input":"2025-01-26T15:14:18.299536Z","iopub.status.idle":"2025-01-26T15:14:18.306878Z","shell.execute_reply.started":"2025-01-26T15:14:18.299512Z","shell.execute_reply":"2025-01-26T15:14:18.305946Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def plot_precision_recall_curve(all_labels, all_scores, class_names):\n    \"\"\"\n    Plots precision-recall curves for all classes.\n    Args:\n        all_labels: List of ground truth labels.\n        all_scores: List of predicted scores for each class.\n        class_names: List of class names.\n    \"\"\"\n    for i, class_name in enumerate(class_names):\n        y_true = [int(l == i) for l in all_labels]\n        y_scores = [s[i] for s in all_scores]\n        precision, recall, _ = precision_recall_curve(y_true, y_scores)\n        pr_auc = auc(recall, precision)\n        plt.plot(recall, precision, label=f\"{class_name} (AUC={pr_auc:.2f})\")\n\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.title(\"Precision-Recall Curve\")\n    plt.legend()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:13:46.700378Z","iopub.execute_input":"2025-01-26T15:13:46.700682Z","iopub.status.idle":"2025-01-26T15:13:46.706004Z","shell.execute_reply.started":"2025-01-26T15:13:46.700655Z","shell.execute_reply":"2025-01-26T15:13:46.704825Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Move model to device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Evaluate on validation/test set\nmAP, recall = evaluate_model(model, valid_loader, device)\n\n# Precision-recall curve (optional)\n# Assuming you collect `all_labels` and `all_scores` during evaluation\nplot_precision_recall_curve(all_labels, all_scores, [\"background\", \"Bus\", \"Truck\", \"Motorcycle\", \"Car\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:13:51.145637Z","iopub.execute_input":"2025-01-26T15:13:51.146004Z","iopub.status.idle":"2025-01-26T15:13:55.388964Z","shell.execute_reply.started":"2025-01-26T15:13:51.145959Z","shell.execute_reply":"2025-01-26T15:13:55.387825Z"}},"outputs":[{"name":"stdout","text":"mAP: 0.7398, Recall: 1.2000\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-b54530de23a7>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Precision-recall curve (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Assuming you collect `all_labels` and `all_scores` during evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot_precision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"background\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Bus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Truck\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Motorcycle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Car\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'all_labels' is not defined"],"ename":"NameError","evalue":"name 'all_labels' is not defined","output_type":"error"}],"execution_count":35}]}